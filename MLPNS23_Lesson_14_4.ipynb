{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMcZ8jJF4BRMku7xpfnInYg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertoBassanoni/MLPNS_ABassanoni/blob/main/MLPNS23_Lesson_14_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Model Performance:\n",
        "\n",
        "Come misurare l'accuratezza e il bilancio complessivo della precisione? Per valutare l'accuratezza di un modello uso delle metriche di distanza tra l'osservazione e la predizione. Abbiamo visto che a seconda del tipo di variabile bisogna definire un concetto adeguato di distanza. Nel contesto semplice della predizione di una classe binaria, in cui posso avere T true o F false, come bilanciamo gli errori?\n",
        "\n",
        "Si definiscono:\n",
        "\n",
        "TP -> True Positive\n",
        "FP -> False Positive\n",
        "TN -> True Negative\n",
        "FN -> False Negative\n",
        "\n",
        "Posso definire delle formule matematiche che sono fondamentalmente delle metriche di precisione:\n",
        "\n",
        "- Precision **$\\frac{TP}{TP+FP}$**\n",
        "\n",
        "- Recall **$\\frac{TP}{TP+FN}$**\n",
        "\n",
        "- Accuracy **$\\frac{TP+TN}{TP+TN+FP+FN}$**\n",
        "\n",
        "- F-Score **$\\frac{TP}{TP + 1/2(FP+FN)}$**\n",
        "\n",
        "Un altra tecnica di accuratezza sono le ROC curves, ossia le receiver operating characteristic. Ovverosia, valutiamo come cambia la precisione dal tipo di meccanismo di estrazione del mio subset di dati. Se ho 100 alberi e 70 alberi dicono che il paziente X è positivo per una malattia e 30 alberi no, allora il paziente ha il 70% di probabilità di avere una malattia. Nel campo medico però io devo prendere una decisione binaria. Devo dunque decidere una threshold per classificare la cosa come un true positive TP o un false positive FP, e genericamente Sklearn genericamente nel random forest assegna per maggioranza (51 su 49 alberi danno positivo, allora è positivo!), ma posso dare una threshold più alta (ad esempio il 90%). Se il mio modello è probabilistico ed ho la possibilità di scegliere questa threshold, posso valutare le potenzialità del modello scegliendo threshold diverse. Le curve ROC fanno sì che ogni modello diventa una curva su cui fitto il false positive rate sul true positive rate. Vogliamo stare genericamente \"in alto a sinistra\", ossia nel flesso della curva, dove ho un true positive rate massimo e il false positive rate minimo. "
      ],
      "metadata": {
        "id": "dgWGOlNSNUoG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Encoding Categorical Variables:\n",
        "\n",
        "Se ho delle variabili categoriche, come le posso sistemare? Ad esempio, nella clinica di un veterniario abbiamo dei dataset su degli animali, e conosciamo la specie, l'età, e il peso. L'età e il peso sono delle variabili continue che posso trattare in maniera ordinale, mentre invece le variabili categoriche quali la specie richiedono un encoding diverso che sia più comodo.\n",
        "\n",
        "Potrei fare un:\n",
        "\n",
        "- numerical encoding: assegno un numero per ogni diversa variabile della specie;\n",
        "\n",
        "Uno dei problemi del numerical encoding è che richiede la creazione di un ordine delle variabili che in realtà non esiste!\n",
        "\n",
        "- one-hot encoding: cambio ogni variabile categorica in una variabile binaria;\n",
        "\n",
        "Uno dei problemi del one-hot encoding è che ho un'alta inflazione di variabili, e un altro problema è il fatto che le variabili sono strettamente correlate, ovverosia io so che ogni animale ha SOLO una specie, ma il mio codice no. \n",
        "\n",
        "Esempio che vediamo è un random forest fatto per stimare il prezzo di alcune case all'asta, in cui usiamo sia one-hot encoding che numerical encoding come prova. Per approfondimento, se ci vuoi dare un occhio. \n",
        "\n",
        "E' importante fare feature_importance per stimare quale variabile è determinante nelle predizioni del modello. Il one-hot encoding ha come altro difetto quello di alterare la feature_importance del mio modello, semplicemente perché non ho più la variabile! "
      ],
      "metadata": {
        "id": "8lza27hOROxe"
      }
    }
  ]
}