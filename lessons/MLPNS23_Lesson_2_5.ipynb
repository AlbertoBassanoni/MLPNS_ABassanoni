{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO/WlqSgo5kcbxZr8VW2D7M",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AlbertoBassanoni/MLPNS_ABassanoni/blob/main/lessons/MLPNS23_Lesson_2_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generative AI: Autoencoders\n",
        "\n",
        "La storia del generative AI è molto giovane, e parte dal 2014 coi primi modelli generativi, in cui si va oltre al concetto di classificazione e regressione che sono le uniche cose che al momento sono permesse dal Machine Learning. \n",
        "\n",
        "##Short recap on CNN:\n",
        "\n",
        "Abbiamo visto che i CNN sono una combinazione di multilinear regressions fatte a più layers. Abbiamo parlato di layer fully connected e di layer sparcely connected, abbiamo visto che ogni layer è una matrice che rappresenta delle combinazioni lineari. Ogni operazione che si fa è lineare in un neural network, e ciò significa che sono invertibili, e di conseguenza quando si traina il modello mediante backpropagation per trovare i pesi giusti è possibile farlo. Abbiamo visto quanto sia importante fare le giuste scelte architettoniche per il nostro neural network, e abbiamo dato alcune regole per farlo. Se ho una loss function molto noisy, devo aggiustare il learning rate. In una situazione di sbalzi estremi della loss function, è bene cambiare l'activation function. \n",
        "\n",
        "## Generative AI:\n",
        "\n",
        "Applicazioni divertenti delle AI, prendere delle foto e cambiare alcune cose, ad esempio da foto di zebre voglio farle diventare delle foto di cavalli. Quindi abbiamo image generation, 3d shape generation, semantic image to photo translation, text to speech generator, speech to speech conversion, text generation, music generation, image resolution increase, image-to-image conversion. \n",
        "\n",
        "Fondamentalmente, il mio neural network crea dei nuovi dati. Stiamo entrando in un'era in cui una generative AI quale ChatGPT diventa molto importante. \n",
        "\n",
        "Un esempio che abbiamo sono i diffusive generative models, che fondamentalmente introducono del noise all'interno delle immagini in input e provano a ricostruirle rimuovendo il noise. Ad esempio, nel nostro caso abbiamo un dataset di fiori, e vogliamo che il network impari dal dataset di fiori e che mandi fuori in output dei nuovi fiori diversi da quelli di prima. Abbiamo un esempio simile è anche il codice che crea nuove scritte dal dataset storico degli hand digits.\n",
        "\n",
        "## Autoencoders:\n",
        "\n",
        "Abbiamo tutti gli elementi architettonici del neural network, solo che li meddiamo assieme in una maniera innovativa. Quello che noi vogliamo fare è approssimare una complex function con una serie di linear functions, e possiamo pensare agli hidden layers come un latent space. Se il mio latent space diminuisce di size rispetto all'input space, posso pensare che ho fatto una compressione non lineare dei miei dati di input (una dimensionality reduction), e quindi costruisco un autoencoder come un insieme di un encoder e di un decoder. Dopo aver compressato l'input space, lo riallargo fino a farlo tornare alla dimensione iniziale. Tipicamente, una prima applicazione di questi autoencoders è quello di far ricreare dal neural network la stessa immagine che gli ho dato dentro all'inizio. Se all'inizio ho un immagine che è low resolution e voglio sputare fuori un immagine a high resolution, vorrei che l'output space sia di dimensione più grande rispetto all'inizio. \n",
        "\n",
        "Abbiamo a che fare con un autoencoder per image reconstruction, che è un problema di regressione. Quindi userò come loss function una mean_squared_error e una linear activation alla fine, tuttavia non ottengo risultati ottimi. Ma dal momento che io ho solo pixel bianchi e neri, provo a cambiare attivazione con una sigmoid alla fine. L'ultimo caso è rimuovere la scala dei grigi mediante una binary_crossentropy. \n",
        "\n",
        "## Altri modelli generativi:\n",
        "\n",
        "Altre famiglie di generative AI sono:\n",
        "\n",
        "- GAN: adversarial training. Qui c'è un generatore che crea le immagini, a partire da rumore bianco, e il discriminatore classifica l'immagine dal generatore come reale o fake, e ci sono due generative NN che vanno in parallelo, e il generatore e il discriminatore sono in competizione, in quanto il generatore cerca di minimizzare la loss function e il discriminatore cerca di massimizzarla. Il tipo di loss function usata si chiama \"minmax loss function\";\n",
        "\n",
        "- VAN: maximise variational lower bound;\n",
        "\n",
        "- Flow-based models: invertible transforms of distributions;\n",
        "\n",
        "- Diffusion models (DDPM): gradually add gaussian noise and then reverse. Venivano usati per migliorare le immagini, rimuovendo noise, ma ora si usano come modelli generativi. Il modello iterativamente aumenta il rumore nell'immagine, e poi prova a ricostruirla;"
      ],
      "metadata": {
        "id": "DVhxtL-t5qLI"
      }
    }
  ]
}